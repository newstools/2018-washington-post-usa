After one of Uber’s driverless cars hit and killed a pedestrian in Arizona Monday, there was broad agreement — among both proponents and detractors of the speedy adoption of self-driving technologies — that this day was coming. Uber abruptly halted testing across North America on Monday after a 49-year old woman, Elaine Herzberg was struck late Sunday night, leaving the rest of the burgeoning industry wondering what the crash means for their future. There was no immediate indication that the brakes would be put on by government authorities or the companies they regulate. Skeptics were hardly surprised that one of the cars they warned were not yet ready had been implicated in a deadly tragedy. And evangelists of the technology had long understood, as one executive from a major car maker put Monday, that “just as a matter of data, this point would come.” “It means we’ve grown up. I don’t mean it in a dismissive way. Growing up is really painful,” said Bryant Walker Smith, an assistant professor of law at the University of South Carolina. “Automated driving is not and will not be perfect. But the status quo is incredibly, tragically imperfect…The same day this woman dies, 100 other people lost their lives in the U.S. in road crashes. And they’re not going to be national news.” But the accounting of blame was just beginning. Missy Cummings, a robotics expert at Duke University who has been critical of the swift rollout of driverless technology across the country, said the computer-vision systems for self-driving cars are “deeply flawed” and can be “incredibly brittle,” particularly in unfamiliar circumstances. Companies have not been required by the federal government to prove that their robotic driving systems are safe. “We’re not holding them to any standards right now,” Cummings said, arguing that the National Highway Traffic Safety Administration should provide real supervision. Uber’s moratorium on testing includes San Francisco, Phoenix, Pittsburgh and Toronto. Sunday’s crash was believed to be the first fatality in any testing program involving autonomous vehicles. The National Transportation Safety Board opened an investigation into the crash, NTSB spokesman Eric Weiss said. “Our hearts go out to the victim’s family. We are fully cooperating with local authorities in their investigation of this incident,” an Uber spokeswoman said. The vehicle was in autonomous mode at the time of the crash, though a driver was behind the wheel, Tempe police said in a statement. The crash occurred about 10 p.m. Sunday in the area of Curry Road and Mill Avenue, a busy intersection with multiple lanes in every direction. Police said the vehicle was northbound approaching Curry Road when a woman, identified as 49-year-old Elaine Herzberg, crossing from the west side of street, was struck. She died at a hospital, the department said. Federal transportation officials have relied on voluntary safety reporting to oversee the burgeoning industry, which has emphasized the life-saving potential of the technology in arguing against government mandates. Arizona has aggressively courted driverless tech firms, based largely on its light regulatory touch. That approach has consequences, Cummings said. “If you’re going take that first step out, then you’re also going to be [the] first entity to have to suffer these kinds of issues,” she said. Driverless technology firms generally say they painstakingly map an area digitally before running their vehicles there, so that the vehicles essentially have banked information about the surroundings that can be compared on the fly to what cameras and sensors are picking up at any moment. Tempe police said Herzberg was “walking outside of the crosswalk” when she was struck. “Just because you map an area doesn’t mean your computer system is necessarily going to pick up a pedestrian, particularly one that wasn’t in a cross walk,” Cummings said. Another industry-wide issue is to what extent autonomous vehicles can deal with unanticipated problems. “The car cameras, the vision systems, they don’t perform inductively, meaning they can’t guess about the appearance of someone in a particular place and time,” Cummings said. “Pedestrians get hit by human drivers all the time for similar reasons,” though the exact cause of this crash remains unclear, she said. Timothy Carone, an associate teaching professor specializing in autonomous systems at the University of Notre Dame, said fatal crashes involving autonomous vehicles, while tragic, will become become more commonplace as testing is introduced and further expanded. The road testing is the only way the systems can learn and adjust to their environments, eventually reaching a level of safety that cuts down on the number of motor vehicle deaths overall, he said. “It’s going to be difficult to accept the deaths … but at some point you’ll start to see the curve bend,” he said. “The fact is these things will save lives and we need to get there.” He compared the self-driving rollout to the early history of the aviation industry, which was beset by safety incidents in the early years of commercial flight, but has now gained near-universal respect as the safest form of mass transportation. “Hopefully it happens much faster and with a much shorter time scale,” he said of autonomous vehicles. Carone said that if the self-driving technology was ultimately responsible for Sunday’s fatality, Uber and authorities will have to “interrogate” the system to determine what went wrong. “It’s not just one thing that goes wrong –there’s a series of several to maybe several thousand steps that led to the death,” said Carone, author of the forthcoming book “Future Automation – Changes to Lives and to Businesses.”  Using data, he said, “They have to figure out, and determine if they can figure out, ‘why did the system make a decision that caused the death?’” The incident trains a national lens on Uber’s self-driving program, which it has ambitiously invested in to position itself as a key player in the world of autonomous driving. The company launched robot-driven Volvo trucks, with human backup drivers, on Arizona highways in November. Sunday’s crash wasn’t the first Uber’s self-driving vehicles were involved in, however. It wasn’t even the first such crash in Tempe. Last March the company temporarily suspended its self-driving fleet after a Volvo XC90 overturned when another driver failed to yield, according to Tempe police. Authorities said the Uber, which was manned by a backup driver, was not at fault. But it was the first major crash involving the company’s self-driving fleet. Uber CEO Dara Khosrowshahi said in a tweet that the company was working to learn what went wrong. “Some incredibly sad news out of Arizona,” he said. “We’re thinking of the victim’s family as we work with local law enforcement to understand what happened.” The crash, for the first time, raised numerous, non-hypothetical questions about who is liable in the event of a pedestrian death involving an autonomous vehicle. Matt Henshon, a Boston lawyer who has written and spoken widely on artificial intelligence and self-driving cars, said that while a civil suit would be fairly straightforward, the question of potential criminal liability is much more complicated. Could the human driver have intervened? Were developers negligent in their design and rollout of the software? Was a non-working sensor missed by inspectors? “The analogy is auto pilot, in the airline case, where you put it on autopilot but the pilot still remains legally responsible,” he said. “Would they have been able to do something?” He said it raised a key question: “Who had ultimate responsibility, the human driver or the car itself?” he asked. But even if the car was deemed responsible, mechanical and software-related questions would also come up. “What bug was in there?” he said. “Was it reasonable for somebody to miss the bug?” A civil case would be much more straightforward. “If I’m representing the decedent … I’m suing the city for allowing everyone to do it,” he said. “But Uber’s my main target.” A spokesman for Arizona Gov. Doug Ducey (R), whose administration has provided a more permissive regulatory environment for deploying driverless cars than in states such as California, said “our hearts go out to the victim involved.” “Safety is our top priority,” said spokesman Patrick Ptak, who did not address a question on whether the death might change anything about the state’s policies. local  gridlock Dallas shooting updates News and analysis on the deadliest day for police since 9/11. post_newsletter353 follow-dallas true endOfArticle false Local Headlines newsletter Daily headlines about the Washington region. Please provide a valid email address. Ptak said Ducey’s “latest executive order provides enhanced enforcement measures and clarity on responsibility in these accidents.” This is a developing story. Check back for updates. Peter Holley contributed to this report.